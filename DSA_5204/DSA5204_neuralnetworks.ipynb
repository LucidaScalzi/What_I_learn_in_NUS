{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preface\n",
    "\n",
    "In this notebook, we introduce basics of building neural network models using the `keras` API over the `tensorflow` library. This significantly simplifies model building and prototyping.\n",
    "\n",
    "Install `tensorflow` (which now contains the `keras` API under `tf.keras`) by issuing\n",
    "\n",
    "```\n",
    "$pip install tensorflow\n",
    "```\n",
    "\n",
    "We will assume that you are using tensorflow v2.0.0 or later. You can check this by\n",
    "```python\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "sns.set(font_scale=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset\n",
    "\n",
    "The MNIST dataset (http://yann.lecun.com/exdb/mnist/) is one of the simplest classification models. \n",
    "\n",
    "It consists of a collection of hand-written digits from 0 to 9. The goal is to build a classifier for this 10-class multi-class classification problem.\n",
    "\n",
    "The dataset can be conveniently imported through the `tf.keras.datasets` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Let's first check the data shape and format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, each input sample is a 28x28 picture, with each pixel a grayscale value from 0-255. \n",
    "\n",
    "We will perform the following preprocessing:\n",
    "  * Flatten the input into a data matrix [num_samples, 28, 28] $\\rightarrow$ [num_samples, 784]\n",
    "  * Rescale the pixel values from [0,255] to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 784) / 255.0\n",
    "x_test = x_test.reshape(-1, 784) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us look at the format of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are the actual numerical values. But for this classification problem we should not use the ordinal data as is. Instead, we convert them into a one-hot encoding, e.g.\n",
    "$$\n",
    "    5 \\rightarrow [0, 0, 0, 0, 0, 1, 0, 0, 0, 0] \\\\\n",
    "    3 \\rightarrow [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "$$\n",
    "\n",
    "This can be done calling `tf.keras.utils.to_categorical` on the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a simple neural network\n",
    "\n",
    "Here we will build and train a simple neural network for this classification problem.\n",
    "\n",
    "We will use the `Sequential` model API. A *model* in keras represents a high level abstraction of a neural network. It consists of a collection of *layers*, and training/evaluation and other common tasks are all handled at the model level.\n",
    "\n",
    "The *sequential* model is a special type of models where it is a linear stack of layers, and will suffice for our current task. In future demos we will explore other types of models supported by `Keras`. For more information, you may check here: https://keras.io/models/about-keras-models/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to build a simple 1-hidden-layer (shallow) neural network in the form of \n",
    "$$\n",
    "    h = g(Wx + c) \\\\\n",
    "    y = Vh + b\n",
    "$$\n",
    "We will use the ReLU activation\n",
    "$$\n",
    "    g(z) = \\max(0, z)\n",
    "$$\n",
    "The number of hidden units is given by the first dimension of W (or the dimension of c) and the number of output units is 10, since we are considering a 10-class classification problem.\n",
    "\n",
    "Both of these layers can be implemented by the `Dense` layer type from `tf.keras.layers`. We will first use a hidden dimension of 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling and Training\n",
    "\n",
    "Now, let us specify losses and optimizers using the `compile` method and train the neural network using the `fit` method.\n",
    "\n",
    "Here, we will use the *cross-entropy* loss and the *SGD* optimizer, which stands for stochastic gradient descent. We have only introduced the usual gradient descent in class, but we will discuss its extension to the stochastic case to handle large datasets in a later lecture. By setting `batch_size` to be equal to the size of the training set, SGD is equivalent to GD.\n",
    "\n",
    "In the `compile` method, we can also specify additional quantities to monitor during training, in addition to the loss. Recall that we are using the cross-entropy loss as a surrogate of the accuracy (0-1 loss), so let us monitor the accuracy also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(learning_rate=0.25), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train the model.\n",
    "\n",
    "We are going to use the inefficient GD, which requires batch_size to be set to the total number of samples. To make training faster, we are going to only use the first 5000 data points for faster training.\n",
    "\n",
    "Here `epochs` refers to the number of sweeps through our training set. Since we are doing GD, each iteration is one sweep, and hence one epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:5000]\n",
    "y_train = y_train[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=x_train,\n",
    "                    y=y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size=x_train.shape[0],\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us examine the training curves to see how we are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.plot(y=['loss', 'val_loss'], title='Loss')\n",
    "history.plot(y=['accuracy', 'val_accuracy'], title='Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of our Model\n",
    "\n",
    "Since we are faced with a classification problem, there is more than just accuracy we care about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report\n",
    "\n",
    "This is a handy function from the `sklearn` library. It outputs the 1 vs all precision, recall, f1-score and support for each class. This is most useful when you have unbalanced datasets (not the case here). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_test.argmax(1), y_pred=y_test_predict.argmax(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "We can also look at the so-called *confusion matrix*, which is a matrix whose $i,j$ entry represents the number of samples  belong to class $i$ that was classified as class $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmatrix = confusion_matrix(y_true=y_test.argmax(1), y_pred=y_test_predict.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use `sns.heatmap` to visualize the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cmatrix, annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get rid of the diagonal values (representing the correctly classified samples) for a clearer view of the main confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(cmatrix, 0)\n",
    "sns.heatmap(cmatrix, annot=True, fmt=\"d\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "259.99px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
